{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "mFvQVjKeGy5N",
        "outputId": "843b3acc-1cb9-4cb8-929d-e47471ea44e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>JobPosting_Key</th>\n",
              "      <th>job_title_short</th>\n",
              "      <th>CountryName</th>\n",
              "      <th>company_name</th>\n",
              "      <th>Skill_Name</th>\n",
              "      <th>skill_text</th>\n",
              "      <th>remote_flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>data analyst</td>\n",
              "      <td>mexico</td>\n",
              "      <td>hewlett packard enterprise</td>\n",
              "      <td>['r', 'nosql', 'sql', 'python', 'excel', 'powe...</td>\n",
              "      <td>r nosql sql python excel power bi sap tableau</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>data engineer</td>\n",
              "      <td>germany</td>\n",
              "      <td>alpha augmented services</td>\n",
              "      <td>['c#', 'sql', 'azure', 'docker', 'python', 'ai...</td>\n",
              "      <td>c# sql azure docker python airflow dax jenkins...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>data engineer</td>\n",
              "      <td>united states</td>\n",
              "      <td>southwest research institute</td>\n",
              "      <td>['aws', 'matlab', 'tensorflow', 'python', 'jav...</td>\n",
              "      <td>aws matlab tensorflow python java pytorch c++ ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>data engineer</td>\n",
              "      <td>sudan</td>\n",
              "      <td>kristina daniel</td>\n",
              "      <td>['aws', 'gitlab', 'bash', 'puppet', 'python', ...</td>\n",
              "      <td>aws gitlab bash puppet python jenkins git ansi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>data engineer</td>\n",
              "      <td>united states</td>\n",
              "      <td>smart folks inc</td>\n",
              "      <td>['gcp', 'sql', 'python']</td>\n",
              "      <td>gcp sql python</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   JobPosting_Key job_title_short    CountryName  \\\n",
              "0               2    data analyst         mexico   \n",
              "1               3   data engineer        germany   \n",
              "2               4   data engineer  united states   \n",
              "3               5   data engineer          sudan   \n",
              "4               6   data engineer  united states   \n",
              "\n",
              "                   company_name  \\\n",
              "0    hewlett packard enterprise   \n",
              "1      alpha augmented services   \n",
              "2  southwest research institute   \n",
              "3               kristina daniel   \n",
              "4               smart folks inc   \n",
              "\n",
              "                                          Skill_Name  \\\n",
              "0  ['r', 'nosql', 'sql', 'python', 'excel', 'powe...   \n",
              "1  ['c#', 'sql', 'azure', 'docker', 'python', 'ai...   \n",
              "2  ['aws', 'matlab', 'tensorflow', 'python', 'jav...   \n",
              "3  ['aws', 'gitlab', 'bash', 'puppet', 'python', ...   \n",
              "4                           ['gcp', 'sql', 'python']   \n",
              "\n",
              "                                          skill_text  remote_flag  \n",
              "0      r nosql sql python excel power bi sap tableau            0  \n",
              "1  c# sql azure docker python airflow dax jenkins...            0  \n",
              "2  aws matlab tensorflow python java pytorch c++ ...            0  \n",
              "3  aws gitlab bash puppet python jenkins git ansi...            0  \n",
              "4                                     gcp sql python            1  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "\n",
        "df = pd.read_csv(\"prepared_jobs_dataset.csv\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6Ng-SBSxCIBs"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "df_remote = df[df['remote_flag'] == 1]  # minority class\n",
        "df_onsite = df[df['remote_flag'] == 0]  # majority class\n",
        "\n",
        "df_onsite_sampled = df_onsite.sample(n=len(df_remote), random_state=42)\n",
        "\n",
        "df_balanced = pd.concat([df_remote, df_onsite_sampled]).sample(frac=1, random_state=42)\n",
        "\n",
        "# Now df_balanced is used for feature extraction and modeling\n",
        "df = df_balanced\n",
        "tfidf_skills = TfidfVectorizer(max_features=500)\n",
        "X_skills = tfidf_skills.fit_transform(df['skill_text'])\n",
        "tfidf_title = TfidfVectorizer(max_features=200)\n",
        "X_title = tfidf_title.fit_transform(df['job_title_short'])\n",
        "tfidf = TfidfVectorizer(max_features=500)\n",
        "X_tfidf = tfidf.fit_transform(df['skill_text'])\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import scipy\n",
        "\n",
        "# One-hot encoding for CountryName\n",
        "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "X_country = ohe.fit_transform(df[['CountryName']])\n",
        "\n",
        "# Combine TF-IDF and one-hot features\n",
        "X_combined = scipy.sparse.hstack([X_skills, X_title, scipy.sparse.csr_matrix(X_country)])\n",
        "X_combined_dense = X_combined.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "R9Gg5OVzCPFl"
      },
      "outputs": [],
      "source": [
        "y = df['remote_flag']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rjYTf3TXCSRS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_combined_dense, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Apply SMOTE on dense arrays\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "yajulhgvCWWn",
        "outputId": "f62dbf51-5cb7-44b1-ab4b-1d583eadb9d5"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (831334885.py, line 45)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mplt.show()plt.title(\"Confusion Matrix\")plt.ylabel(\"Actual\")plt.xlabel(\"Predicted\")sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0,1], yticklabels=[0,1])plt.figure(figsize=(6,5))cm = confusion_matrix(y_test, y_pred)cm = confusion_matrix(y_test, y_pred)\u001b[39m\n              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=12,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=3,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Save the model and preprocessors\n",
        "import joblib\n",
        "joblib.dump(rf, 'rf_remote_model.joblib')\n",
        "joblib.dump(tfidf_skills, 'tfidf_skills.joblib')\n",
        "joblib.dump(tfidf_title, 'tfidf_title.joblib')\n",
        "joblib.dump(ohe, 'ohe_rf.joblib')\n",
        "\n",
        "# =====  Predictions =====\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# =====  Evaluation =====\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.show()plt.title(\"Confusion Matrix\")plt.ylabel(\"Actual\")plt.xlabel(\"Predicted\")sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0,1], yticklabels=[0,1])plt.figure(figsize=(6,5))cm = confusion_matrix(y_test, y_pred)cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0,1], yticklabels=[0,1])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
