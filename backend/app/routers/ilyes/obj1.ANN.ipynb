{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9550f12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: c:\\Python314\\python.exe\n",
      "Python version: 3.14.0 (tags/v3.14.0:ebf955d, Oct  7 2025, 10:15:03) [MSC v.1944 64 bit (AMD64)]\n",
      "pip: pip 25.3 from C:\\Users\\ILYESS\\AppData\\Roaming\\Python\\Python314\\site-packages\\pip (python 3.14)\n",
      "\n",
      "Using scikit-learn MLPClassifier for ANN-style modelling (no TensorFlow required).\n",
      "pip: pip 25.3 from C:\\Users\\ILYESS\\AppData\\Roaming\\Python\\Python314\\site-packages\\pip (python 3.14)\n",
      "\n",
      "Using scikit-learn MLPClassifier for ANN-style modelling (no TensorFlow required).\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow will be skipped — using scikit-learn MLP instead (no heavy installs required)\n",
    "import sys, subprocess\n",
    "print('Python executable:', sys.executable)\n",
    "print('Python version:', sys.version)\n",
    "try:\n",
    "    pip_ver = subprocess.check_output([sys.executable, '-m', 'pip', '--version'], text=True).strip()\n",
    "    print('pip:', pip_ver)\n",
    "except Exception as e:\n",
    "    print('Could not query pip version:', e)\n",
    "\n",
    "print('\\nUsing scikit-learn MLPClassifier for ANN-style modelling (no TensorFlow required).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad9d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing text...\n",
      "Reducing TF-IDF with SVD...\n",
      "Reducing TF-IDF with SVD...\n",
      "Final ANN/MLP feature shape: (576257, 461)\n",
      "Final ANN/MLP feature shape: (576257, 461)\n",
      "Training MLPClassifier...\n",
      "Training MLPClassifier...\n",
      "Iteration 1, loss = 0.56152374\n",
      "Iteration 1, loss = 0.56152374\n",
      "Validation score: 0.743296\n",
      "Validation score: 0.743296\n",
      "Iteration 2, loss = 0.44030333\n",
      "Iteration 2, loss = 0.44030333\n",
      "Validation score: 0.811616\n",
      "Validation score: 0.811616\n",
      "Iteration 3, loss = 0.33613373\n",
      "Iteration 3, loss = 0.33613373\n",
      "Validation score: 0.850441\n",
      "Validation score: 0.850441\n",
      "Iteration 4, loss = 0.26644291\n",
      "Iteration 4, loss = 0.26644291\n",
      "Validation score: 0.878214\n",
      "Validation score: 0.878214\n",
      "Iteration 5, loss = 0.22389876\n",
      "Iteration 5, loss = 0.22389876\n",
      "Validation score: 0.887484\n",
      "Validation score: 0.887484\n",
      "Iteration 6, loss = 0.19488067\n",
      "Iteration 6, loss = 0.19488067\n",
      "Validation score: 0.898464\n",
      "Validation score: 0.898464\n",
      "Iteration 7, loss = 0.17451412\n",
      "Iteration 7, loss = 0.17451412\n",
      "Validation score: 0.902973\n",
      "Validation score: 0.902973\n",
      "Iteration 8, loss = 0.15853888\n",
      "Iteration 8, loss = 0.15853888\n",
      "Validation score: 0.908296\n",
      "Validation score: 0.908296\n",
      "Iteration 9, loss = 0.14647047\n",
      "Iteration 9, loss = 0.14647047\n",
      "Validation score: 0.909420\n",
      "Validation score: 0.909420\n",
      "Iteration 10, loss = 0.13653869\n",
      "Iteration 10, loss = 0.13653869\n",
      "Validation score: 0.910927\n",
      "Validation score: 0.910927\n",
      "Iteration 11, loss = 0.12839738\n",
      "Iteration 11, loss = 0.12839738\n",
      "Validation score: 0.917147\n",
      "Validation score: 0.917147\n",
      "Iteration 12, loss = 0.12158450\n",
      "Iteration 12, loss = 0.12158450\n",
      "Validation score: 0.916752\n",
      "Validation score: 0.916752\n",
      "Iteration 13, loss = 0.11590566\n",
      "Iteration 13, loss = 0.11590566\n",
      "Validation score: 0.920867\n",
      "Validation score: 0.920867\n",
      "Iteration 14, loss = 0.11137899\n",
      "Iteration 14, loss = 0.11137899\n",
      "Validation score: 0.921896\n",
      "Validation score: 0.921896\n",
      "Iteration 15, loss = 0.10684981\n",
      "Iteration 15, loss = 0.10684981\n",
      "Validation score: 0.923773\n",
      "Validation score: 0.923773\n",
      "Iteration 16, loss = 0.10366037\n",
      "Iteration 16, loss = 0.10366037\n",
      "Validation score: 0.922242\n",
      "Validation score: 0.922242\n",
      "Iteration 17, loss = 0.10032848\n",
      "Iteration 17, loss = 0.10032848\n",
      "Validation score: 0.924072\n",
      "Validation score: 0.924072\n",
      "Iteration 18, loss = 0.09768918\n",
      "Iteration 18, loss = 0.09768918\n",
      "Validation score: 0.925484\n",
      "Validation score: 0.925484\n",
      "Iteration 19, loss = 0.09507935\n",
      "Iteration 19, loss = 0.09507935\n",
      "Validation score: 0.927003\n",
      "Validation score: 0.927003\n",
      "Iteration 20, loss = 0.09235283\n",
      "Iteration 20, loss = 0.09235283\n",
      "Validation score: 0.925388\n",
      "Validation score: 0.925388\n",
      "Iteration 21, loss = 0.09120149\n",
      "Iteration 21, loss = 0.09120149\n",
      "Validation score: 0.928522\n",
      "Validation score: 0.928522\n",
      "Iteration 22, loss = 0.08959051\n",
      "Iteration 22, loss = 0.08959051\n",
      "Validation score: 0.930483\n",
      "Validation score: 0.930483\n",
      "Iteration 23, loss = 0.08758289\n",
      "Iteration 23, loss = 0.08758289\n",
      "Validation score: 0.926237\n",
      "Validation score: 0.926237\n",
      "Iteration 24, loss = 0.08613975\n",
      "Iteration 24, loss = 0.08613975\n",
      "Validation score: 0.928283\n",
      "Validation score: 0.928283\n",
      "Iteration 25, loss = 0.08523684\n",
      "Iteration 25, loss = 0.08523684\n",
      "Validation score: 0.931668\n",
      "Validation score: 0.931668\n",
      "Iteration 26, loss = 0.08374289\n",
      "Iteration 26, loss = 0.08374289\n",
      "Validation score: 0.932397\n",
      "Validation score: 0.932397\n",
      "Iteration 27, loss = 0.08275945\n",
      "Iteration 27, loss = 0.08275945\n",
      "Validation score: 0.930591\n",
      "Validation score: 0.930591\n",
      "Iteration 28, loss = 0.08144190\n",
      "Iteration 28, loss = 0.08144190\n",
      "Validation score: 0.931919\n",
      "Validation score: 0.931919\n",
      "Iteration 29, loss = 0.08090858\n",
      "Iteration 29, loss = 0.08090858\n",
      "Validation score: 0.928522\n",
      "Validation score: 0.928522\n",
      "Iteration 30, loss = 0.07942426\n",
      "Iteration 30, loss = 0.07942426\n",
      "Validation score: 0.929718\n",
      "Validation score: 0.929718\n",
      "Iteration 31, loss = 0.07921881\n",
      "Iteration 31, loss = 0.07921881\n",
      "Validation score: 0.931620\n",
      "Validation score: 0.931620\n",
      "Iteration 32, loss = 0.07803050\n",
      "Iteration 32, loss = 0.07803050\n",
      "Validation score: 0.932780\n",
      "Validation score: 0.932780\n",
      "Iteration 33, loss = 0.07741650\n",
      "Iteration 33, loss = 0.07741650\n",
      "Validation score: 0.934371\n",
      "Validation score: 0.934371\n",
      "Iteration 34, loss = 0.07685860\n",
      "Iteration 34, loss = 0.07685860\n",
      "Validation score: 0.930448\n",
      "Validation score: 0.930448\n",
      "Iteration 35, loss = 0.07642796\n",
      "Iteration 35, loss = 0.07642796\n",
      "Validation score: 0.933450\n",
      "Validation score: 0.933450\n",
      "Iteration 36, loss = 0.07544343\n",
      "Iteration 36, loss = 0.07544343\n",
      "Validation score: 0.934383\n",
      "Validation score: 0.934383\n",
      "Iteration 37, loss = 0.07561425\n",
      "Iteration 37, loss = 0.07561425\n",
      "Validation score: 0.933605\n",
      "Validation score: 0.933605\n",
      "Iteration 38, loss = 0.07449872\n",
      "Iteration 38, loss = 0.07449872\n",
      "Validation score: 0.935806\n",
      "Validation score: 0.935806\n",
      "Iteration 39, loss = 0.07437168\n",
      "Iteration 39, loss = 0.07437168\n",
      "Validation score: 0.935375\n",
      "Validation score: 0.935375\n",
      "Iteration 40, loss = 0.07344131\n",
      "Iteration 40, loss = 0.07344131\n",
      "Validation score: 0.935973\n",
      "Validation score: 0.935973\n",
      "Iteration 41, loss = 0.07329729\n",
      "Iteration 41, loss = 0.07329729\n",
      "Validation score: 0.933545\n",
      "Validation score: 0.933545\n",
      "Iteration 42, loss = 0.07303538\n",
      "Iteration 42, loss = 0.07303538\n",
      "Validation score: 0.934203\n",
      "Validation score: 0.934203\n",
      "Iteration 43, loss = 0.07247570\n",
      "Iteration 43, loss = 0.07247570\n",
      "Validation score: 0.932349\n",
      "Validation score: 0.932349\n",
      "Iteration 44, loss = 0.07239729\n",
      "Iteration 44, loss = 0.07239729\n",
      "Validation score: 0.933880\n",
      "Validation score: 0.933880\n",
      "Iteration 45, loss = 0.07153576\n",
      "Iteration 45, loss = 0.07153576\n",
      "Validation score: 0.936691\n",
      "Validation score: 0.936691\n",
      "Iteration 46, loss = 0.07171971\n",
      "Iteration 46, loss = 0.07171971\n",
      "Validation score: 0.932959\n",
      "Validation score: 0.932959\n",
      "Iteration 47, loss = 0.07095627\n",
      "Iteration 47, loss = 0.07095627\n",
      "Validation score: 0.936332\n",
      "Validation score: 0.936332\n",
      "Iteration 48, loss = 0.07124516\n",
      "Iteration 48, loss = 0.07124516\n",
      "Validation score: 0.934634\n",
      "Validation score: 0.934634\n",
      "Iteration 49, loss = 0.07074099\n",
      "Iteration 49, loss = 0.07074099\n",
      "Validation score: 0.932505\n",
      "Validation score: 0.932505\n",
      "Iteration 50, loss = 0.07048067\n",
      "Iteration 50, loss = 0.07048067\n",
      "Validation score: 0.933533\n",
      "Validation score: 0.933533\n",
      "\n",
      "Accuracy: 0.9371767576489726\n",
      "\n",
      "ROC AUC: 0.9737837100830516\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.93    104500\n",
      "           1       0.90      0.98      0.94    104515\n",
      "\n",
      "    accuracy                           0.94    209015\n",
      "   macro avg       0.94      0.94      0.94    209015\n",
      "weighted avg       0.94      0.94      0.94    209015\n",
      "\n",
      "\n",
      "DONE ✔ — model and preprocessing saved as joblib files.\n",
      "\n",
      "Accuracy: 0.9371767576489726\n",
      "\n",
      "ROC AUC: 0.9737837100830516\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.93    104500\n",
      "           1       0.90      0.98      0.94    104515\n",
      "\n",
      "    accuracy                           0.94    209015\n",
      "   macro avg       0.94      0.94      0.94    209015\n",
      "weighted avg       0.94      0.94      0.94    209015\n",
      "\n",
      "\n",
      "DONE ✔ — model and preprocessing saved as joblib files.\n"
     ]
    }
   ],
   "source": [
    "# ANN (MLP) Model for Predicting Remote Job Postings\n",
    "# This notebook trains a Multi-Layer Perceptron (MLP) classifier to predict if a job posting is remote.\n",
    "# It uses TF-IDF for text vectorization, SVD for dimensionality reduction, one-hot encoding for countries,\n",
    "# and oversampling to handle class imbalance. The model is evaluated and saved for later use.\n",
    "\n",
    "# 1) IMPORTS\n",
    "# Import necessary libraries for data processing, machine learning, and evaluation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, f1_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 2) LOAD & PREPARE DATA\n",
    "# Load the dataset and prepare features and target\n",
    "df = pd.read_csv('prepared_jobs_dataset.csv')\n",
    "\n",
    "# Fill missing values in text columns\n",
    "df['skill_text'] = df['skill_text'].fillna('')\n",
    "df['job_title_short'] = df['job_title_short'].fillna('')\n",
    "df['company_name'] = df['company_name'].fillna('')\n",
    "df['CountryName'] = df['CountryName'].fillna('Unknown')\n",
    "\n",
    "# Combine text fields into a single clean text for vectorization\n",
    "df['clean_text'] = (\n",
    "    df['job_title_short'].astype(str) + ' ' +\n",
    "    df['company_name'].astype(str) + ' ' +\n",
    "    df['skill_text'].astype(str)\n",
    " )\n",
    "\n",
    "# Create numeric features: number of skills and title length\n",
    "df['num_skills'] = df['skill_text'].apply(lambda x: len(x.split()))\n",
    "df['title_len'] = df['job_title_short'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Define target: remote flag (1 for remote, 0 otherwise)\n",
    "y = df['remote_flag'] if 'remote_flag' in df.columns else df['job_work_from_home'].apply(lambda x: 1 if x==1 else 0)\n",
    "\n",
    "# 3) TF-IDF + SVD (dimensionality reduction)\n",
    "# Vectorize text using TF-IDF and reduce dimensions with SVD for efficiency\n",
    "print('Vectorizing text...')\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X_text = tfidf.fit_transform(df['clean_text'])\n",
    "\n",
    "print('Reducing TF-IDF with SVD...')\n",
    "svd = TruncatedSVD(n_components=300, random_state=42)\n",
    "X_text_reduced = svd.fit_transform(X_text)   # now dense (important for ANN/MLP)\n",
    "\n",
    "# 4) ONE-HOT COUNTRY\n",
    "# Encode country as one-hot vectors\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "X_country = ohe.fit_transform(df[['CountryName']])\n",
    "\n",
    "# 5) NUMERIC FEATURES (scaled)\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_numeric = scaler.fit_transform(df[['num_skills','title_len']])\n",
    "\n",
    "# 6) FINAL FEATURE MATRIX (dense)\n",
    "# Combine all features into a dense matrix\n",
    "X = np.hstack([X_text_reduced, X_country, X_numeric])\n",
    "print('Final ANN/MLP feature shape:', X.shape)\n",
    "\n",
    "# 7) BALANCE WITH OVERSAMPLING (keeps dense arrays)\n",
    "# Use oversampling to balance classes since remote jobs are minority\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# 8) TRAIN-TEST SPLIT\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42\n",
    " )\n",
    "\n",
    "# 9) BUILD & TRAIN scikit-learn MLP (CPU-friendly)\n",
    "# Define and train the MLP classifier with early stopping\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(512,256,128),  # Three hidden layers\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    batch_size=256,\n",
    "    max_iter=50,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=5,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print('Training MLPClassifier...')\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Save model and preprocessing artifacts for later use\n",
    "joblib.dump(mlp, 'mlp_remote_model.joblib')\n",
    "joblib.dump(tfidf, 'tfidf_for_mlp.joblib')\n",
    "joblib.dump(svd, 'svd_for_mlp.joblib')\n",
    "joblib.dump(ohe, 'ohe_for_mlp.joblib')\n",
    "joblib.dump(scaler, 'scaler_for_mlp.joblib')\n",
    "\n",
    "# 10) EVALUATION\n",
    "# Evaluate the model on test data\n",
    "y_prob = mlp.predict_proba(X_test)[:,1]\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "print('\\nAccuracy:', accuracy_score(y_test, y_pred))\n",
    "print('\\nROC AUC:', roc_auc_score(y_test, y_prob))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('\\nDONE ✔ — model and preprocessing saved as joblib files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5883b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0\n",
      "Remote probability: 0.14110957027466797\n"
     ]
    }
   ],
   "source": [
    "# Prediction Function for Remote Job Model\n",
    "# This cell loads the saved MLP model and preprocessing artifacts,\n",
    "# defines a prediction function for new job postings, and demonstrates usage.\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1) LOAD SAVED MODELS & PROCESSORS\n",
    "# Load the trained MLP model and all preprocessing transformers\n",
    "mlp = joblib.load(\"mlp_remote_model.joblib\")\n",
    "tfidf = joblib.load(\"tfidf_for_mlp.joblib\")\n",
    "svd = joblib.load(\"svd_for_mlp.joblib\")\n",
    "ohe = joblib.load(\"ohe_for_mlp.joblib\")\n",
    "scaler = joblib.load(\"scaler_for_mlp.joblib\")\n",
    "\n",
    "# 2) PREDICTION FUNCTION\n",
    "# Function to predict if a job is remote based on input features\n",
    "def predict_remote(job_title, company_name, skills_text, country):\n",
    "    \"\"\"\n",
    "    Predict whether a job is remote (1) or not (0)\n",
    "    Args:\n",
    "        job_title: Short job title string\n",
    "        company_name: Company name string\n",
    "        skills_text: Skills description string\n",
    "        country: Country name string\n",
    "    Returns:\n",
    "        pred: Binary prediction (0 or 1)\n",
    "        prob: Probability of being remote\n",
    "    \"\"\"\n",
    "    # ---- Build input record ----\n",
    "    # Create a DataFrame for the input\n",
    "    df = pd.DataFrame([{\n",
    "        \"job_title_short\": job_title if job_title else \"\",\n",
    "        \"company_name\": company_name if company_name else \"\",\n",
    "        \"skill_text\": skills_text if skills_text else \"\",\n",
    "        \"CountryName\": country if country else \"Unknown\"\n",
    "    }])\n",
    "\n",
    "    # ---- Build clean_text ----\n",
    "    # Combine text fields as done in training\n",
    "    df[\"clean_text\"] = (\n",
    "        df[\"job_title_short\"] + \" \" +\n",
    "        df[\"company_name\"] + \" \" +\n",
    "        df[\"skill_text\"]\n",
    "    )\n",
    "\n",
    "    # ---- Numeric features ----\n",
    "    # Compute numeric features\n",
    "    df[\"num_skills\"] = df[\"skill_text\"].apply(lambda x: len(x.split()))\n",
    "    df[\"title_len\"] = df[\"job_title_short\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "    # PREPROCESSING PIPELINE\n",
    "    # Apply the same preprocessing steps as in training\n",
    "\n",
    "    # 1. TF-IDF → SVD\n",
    "    # Vectorize text and reduce dimensions\n",
    "    X_text = tfidf.transform(df[\"clean_text\"])\n",
    "    X_text_red = svd.transform(X_text)\n",
    "\n",
    "    # 2. One-hot encode country (ensure correct feature alignment)\n",
    "    # Encode country\n",
    "    X_country = ohe.transform(df[[\"CountryName\"]])\n",
    "\n",
    "    # 3. Scale numeric\n",
    "    # Scale numeric features\n",
    "    X_numeric = scaler.transform(df[[\"num_skills\", \"title_len\"]])\n",
    "\n",
    "    # Combine all features\n",
    "    # Stack features horizontally\n",
    "    X = np.hstack([X_text_red, X_country, X_numeric])\n",
    "\n",
    "    # 3) MODEL PREDICTION\n",
    "    # Get prediction and probability\n",
    "    prob = mlp.predict_proba(X)[0, 1]\n",
    "    pred = int(prob >= 0.5)\n",
    "\n",
    "    return pred, float(prob)\n",
    "\n",
    "# 4) EXAMPLE USAGE\n",
    "# Demonstrate the prediction function with sample data\n",
    "pred, prob = predict_remote(\n",
    "    job_title=\"Senior Python Engineer\",\n",
    "    company_name=\"Google\",\n",
    "    skills_text=\"python backend API docker kubernetes tensorflow\",\n",
    "    country=\"USA\"\n",
    ")\n",
    "\n",
    "print(\"Prediction:\", pred)\n",
    "print(\"Remote probability:\", prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
